{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fd80501-3f5c-439b-a4ca-61e602d5b8b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465b97a4-a3e0-47c3-91d4-be3f4ae3b223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from faker import Faker\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Faker with Spanish locale\n",
    "fake = Faker('es_ES')\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configuration\n",
    "SK_COUNTRY = 1.0  # Venezuela\n",
    "COUNTRY_NAME = \"Venezuela\"\n",
    "START_DATE = datetime(2023, 1, 1)\n",
    "END_DATE = datetime(2025, 12, 31)\n",
    "\n",
    "# Sales fact configuration - 3 months of dense data\n",
    "SALES_START_DATE = datetime(2025, 7, 1)  # July 2025\n",
    "SALES_END_DATE = datetime(2025, 9, 30)   # September 2025\n",
    "SALES_PER_STORE_PER_DAY = 50  # Average transactions per store per day\n",
    "\n",
    "# Helper function to generate timestamps\n",
    "def random_date(start, end):\n",
    "    return start + timedelta(days=random.randint(0, (end - start).days))\n",
    "\n",
    "# ==================== DIM_CURRENCY ====================\n",
    "def generate_dim_currency():\n",
    "    currencies = [\n",
    "        {\n",
    "            'SK_CURRENCY': 1.0,\n",
    "            'CURRENCY_ABR': 'VES',\n",
    "            'CURRENCY_NAME': 'Bolivar',\n",
    "            'SYMBOL': 'Bs.',\n",
    "            'CREATED_DATE': datetime(2023, 1, 1),\n",
    "            'CREATED_BY': 'SYSTEM',\n",
    "            'LAST_UPD': datetime.now(),\n",
    "            'LAST_UPD_BY': 'SYSTEM',\n",
    "            'DB_EXTRACTION_TIMESTAMP': datetime.now()\n",
    "        },\n",
    "        {\n",
    "            'SK_CURRENCY': 2.0,\n",
    "            'CURRENCY_ABR': 'USD',\n",
    "            'CURRENCY_NAME': 'Dolar Estadounidense',\n",
    "            'SYMBOL': '$',\n",
    "            'CREATED_DATE': datetime(2023, 1, 1),\n",
    "            'CREATED_BY': 'SYSTEM',\n",
    "            'LAST_UPD': datetime.now(),\n",
    "            'LAST_UPD_BY': 'SYSTEM',\n",
    "            'DB_EXTRACTION_TIMESTAMP': datetime.now()\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(currencies)\n",
    "    \n",
    "    # Ensure column order matches table definition\n",
    "    column_order = [\n",
    "        'SK_CURRENCY', 'CURRENCY_ABR', 'CURRENCY_NAME', 'CREATED_DATE', 'CREATED_BY',\n",
    "        'LAST_UPD', 'LAST_UPD_BY', 'SYMBOL', 'DB_EXTRACTION_TIMESTAMP'\n",
    "    ]\n",
    "    \n",
    "    return df[column_order]\n",
    "\n",
    "# ==================== DIM_SUPPLIER ====================\n",
    "def generate_dim_supplier(n_suppliers=10):\n",
    "    suppliers = []\n",
    "    supplier_names = [\n",
    "        'Laboratorios Leti', 'Pfizer Venezuela', 'GSK Venezuela', \n",
    "        'Bayer Venezuela', 'Sanofi Venezuela', 'Novartis Venezuela',\n",
    "        'Johnson & Johnson', 'Abbott Venezuela', 'Merck Venezuela',\n",
    "        'Roche Venezuela', 'AstraZeneca', 'Boehringer Ingelheim'\n",
    "    ]\n",
    "    \n",
    "    for i in range(1, n_suppliers + 1):\n",
    "        supplier = {\n",
    "            'SK_SUPPLIER': float(i),\n",
    "            'SK_COUNTRY': SK_COUNTRY,\n",
    "            'SUPPLIER': i,\n",
    "            'SUP_NAME': supplier_names[i-1] if i <= len(supplier_names) else f'Proveedor {i}',\n",
    "            'SUP_NAME_SECONDARY': f'SUP{i:03d}',\n",
    "            'SUPPLIER_PARENT': random.choice([0, i]) if i > 3 else 0,\n",
    "            'SUP_STATUS': random.choice(['A', 'A', 'A', 'I']),\n",
    "            'PRE_MARK_IND': random.choice(['Y', 'N']),\n",
    "            'EDI_SUPP_AVAILABLE_IND': random.choice(['Y', 'N']),\n",
    "            'STATUS_UPD_BY_RMS': 'Y',\n",
    "            'RET_ALLOW_IND': random.choice(['Y', 'N']),\n",
    "            'CONTACT_NAME': fake.name(),\n",
    "            'CONTACT_PHONE': fake.phone_number(),\n",
    "            'CONTACT_EMAIL': fake.email(),\n",
    "            'CREATED_DATE': datetime(2023, 1, 1),\n",
    "            'CREATED_BY': 'SYSTEM',\n",
    "            'LAST_UPD': datetime.now(),\n",
    "            'LAST_UPD_BY': 'SYSTEM',\n",
    "            'DB_EXTRACTION_TIMESTAMP': datetime.now()\n",
    "        }\n",
    "        suppliers.append(supplier)\n",
    "    \n",
    "    df = pd.DataFrame(suppliers)\n",
    "    \n",
    "    # Ensure column order matches table definition\n",
    "    column_order = [\n",
    "        'SK_SUPPLIER', 'SK_COUNTRY', 'SUPPLIER', 'SUP_NAME', 'SUP_NAME_SECONDARY',\n",
    "        'SUPPLIER_PARENT', 'SUP_STATUS', 'PRE_MARK_IND', 'EDI_SUPP_AVAILABLE_IND',\n",
    "        'STATUS_UPD_BY_RMS', 'RET_ALLOW_IND', 'CONTACT_NAME', 'CONTACT_PHONE',\n",
    "        'CONTACT_EMAIL', 'CREATED_DATE', 'CREATED_BY', 'LAST_UPD', 'LAST_UPD_BY',\n",
    "        'DB_EXTRACTION_TIMESTAMP'\n",
    "    ]\n",
    "    \n",
    "    return df[column_order]\n",
    "\n",
    "# ==================== DIM_PRODUCT ====================\n",
    "def generate_dim_product(n_suppliers=10, products_per_supplier=100):\n",
    "    products = []\n",
    "    sk_product = 1\n",
    "    \n",
    "    # Product categories for pharmaceutical retail\n",
    "    departments = [\n",
    "        {'dept': 1, 'name': 'Medicamentos', 'division': 1, 'div_name': 'Farmacia'},\n",
    "        {'dept': 2, 'name': 'Cuidado Personal', 'division': 2, 'div_name': 'Belleza y Cuidado'},\n",
    "        {'dept': 3, 'name': 'Nutricion', 'division': 3, 'div_name': 'Alimentos y Bebidas'},\n",
    "        {'dept': 4, 'name': 'Infantil', 'division': 4, 'div_name': 'Bebe y Mama'}\n",
    "    ]\n",
    "    \n",
    "    classes = {\n",
    "        1: [{'class': 101, 'name': 'Analgesicos'}, {'class': 102, 'name': 'Antibioticos'}, {'class': 103, 'name': 'Vitaminas'}],\n",
    "        2: [{'class': 201, 'name': 'Shampoo'}, {'class': 202, 'name': 'Jabones'}, {'class': 203, 'name': 'Cremas'}],\n",
    "        3: [{'class': 301, 'name': 'Suplementos'}, {'class': 302, 'name': 'Bebidas'}, {'class': 303, 'name': 'Snacks'}],\n",
    "        4: [{'class': 401, 'name': 'Panales'}, {'class': 402, 'name': 'Formulas'}, {'class': 403, 'name': 'Accesorios'}]\n",
    "    }\n",
    "    \n",
    "    brands = ['Generico', 'Premium', 'Natural', 'Essential', 'Advanced', 'Classic']\n",
    "    \n",
    "    for supplier_id in range(1, n_suppliers + 1):\n",
    "        for _ in range(products_per_supplier):\n",
    "            dept = random.choice(departments)\n",
    "            class_list = classes[dept['dept']]\n",
    "            selected_class = random.choice(class_list)\n",
    "            \n",
    "            item_code = f\"{dept['dept']}{selected_class['class']}{sk_product:06d}\"\n",
    "            \n",
    "            product = {\n",
    "                'SK_PRODUCT': float(sk_product),\n",
    "                'SK_COUNTRY': SK_COUNTRY,\n",
    "                'ITEM': item_code,\n",
    "                'ITEM_DESC': f\"{fake.word().capitalize()} {selected_class['name']} {random.choice(brands)}\",\n",
    "                'ITEM_NUMBER_TYPE': 'SKU',\n",
    "                'ITEM_PARENT': item_code if random.random() > 0.3 else None,\n",
    "                'PACK_IND': random.choice(['Y', 'N']),\n",
    "                'MERCHANDISE_IND': 'Y',\n",
    "                'SUBCLASS': random.randint(1, 5),\n",
    "                'SUB_NAME': f\"SubClase {random.randint(1, 5)}\",\n",
    "                'SUBCLASS_ID': random.randint(1000, 1999),\n",
    "                'CLASS': selected_class['class'],\n",
    "                'CLASS_NAME': selected_class['name'],\n",
    "                'CLASS_ID': selected_class['class'],\n",
    "                'DEPT': dept['dept'],\n",
    "                'DEPT_NAME': dept['name'],\n",
    "                'GROUP_NO': dept['dept'],\n",
    "                'GROUP_NAME': dept['name'],\n",
    "                'DIVISION': dept['division'],\n",
    "                'DIV_NAME': dept['div_name'],\n",
    "                'UNIT': random.randint(1, 10),\n",
    "                'UNIT_NAME': random.choice(['Unidad', 'Caja', 'Frasco', 'Blister']),\n",
    "                'BARCODE': f\"750{random.randint(10000000, 99999999)}\",\n",
    "                'BARCODE_TYPE': 'UPC',\n",
    "                'SELLABLE_IND': 'Y',\n",
    "                'ORDERABLE_IND': 'Y',\n",
    "                'STATUS': random.choice(['A', 'A', 'A', 'I']),\n",
    "                'INVENTORY_IND': 'Y',\n",
    "                'CREATED_DATE': datetime(2023, 1, 1),\n",
    "                'CREATED_BY': 'SYSTEM',\n",
    "                'LAST_UPD': datetime.now(),\n",
    "                'LAST_UPD_BY': 'SYSTEM',\n",
    "                'HIERARCHICAL_NAME': f\"{dept['div_name']}/{dept['name']}/{selected_class['name']}\",\n",
    "                'ITEM_EXCLUDE': random.choice(['Y', 'N']),\n",
    "                'DESC_ITEM_EXCLUDE': '',\n",
    "                'HIERARCHICAL_UNIT': float(dept['dept']),\n",
    "                'X_ORIGEN_SYSTEM': 'RMS',\n",
    "                'OWN_BRAND': random.choice(['Y', 'N']),\n",
    "                'BUD_INT': float(supplier_id),\n",
    "                'BRAND_NAME': random.choice(brands),\n",
    "                'PPV': random.choice(['Y', 'N']),\n",
    "                'MIGRADO': 'N',\n",
    "                'DB_EXTRACTION_TIMESTAMP': datetime.now()\n",
    "            }\n",
    "            products.append(product)\n",
    "            sk_product += 1\n",
    "    \n",
    "    df = pd.DataFrame(products)\n",
    "    \n",
    "    # Ensure column order matches table definition\n",
    "    column_order = [\n",
    "        'SK_PRODUCT', 'SK_COUNTRY', 'ITEM', 'ITEM_DESC', 'ITEM_NUMBER_TYPE', 'ITEM_PARENT',\n",
    "        'PACK_IND', 'MERCHANDISE_IND', 'SUBCLASS', 'SUB_NAME', 'SUBCLASS_ID', 'CLASS',\n",
    "        'CLASS_NAME', 'CLASS_ID', 'DEPT', 'DEPT_NAME', 'GROUP_NO', 'GROUP_NAME', 'DIVISION',\n",
    "        'DIV_NAME', 'UNIT', 'UNIT_NAME', 'BARCODE', 'BARCODE_TYPE', 'SELLABLE_IND',\n",
    "        'ORDERABLE_IND', 'STATUS', 'INVENTORY_IND', 'CREATED_DATE', 'CREATED_BY', 'LAST_UPD',\n",
    "        'LAST_UPD_BY', 'HIERARCHICAL_NAME', 'ITEM_EXCLUDE', 'DESC_ITEM_EXCLUDE',\n",
    "        'HIERARCHICAL_UNIT', 'X_ORIGEN_SYSTEM', 'OWN_BRAND', 'BUD_INT', 'BRAND_NAME', 'PPV',\n",
    "        'MIGRADO', 'DB_EXTRACTION_TIMESTAMP'\n",
    "    ]\n",
    "    \n",
    "    return df[column_order]\n",
    "\n",
    "# ==================== DIM_ORGANIZATION ====================\n",
    "def generate_dim_organization(n_stores=100):\n",
    "    stores = []\n",
    "    \n",
    "    # Venezuelan cities\n",
    "    cities = [\n",
    "        {'name': 'Caracas', 'region': 1, 'region_name': 'Capital', 'lat_range': (10.4, 10.5), 'lon_range': (-66.9, -66.8)},\n",
    "        {'name': 'Maracaibo', 'region': 2, 'region_name': 'Occidente', 'lat_range': (10.6, 10.7), 'lon_range': (-71.7, -71.6)},\n",
    "        {'name': 'Valencia', 'region': 3, 'region_name': 'Centro', 'lat_range': (10.1, 10.2), 'lon_range': (-68.0, -67.9)},\n",
    "        {'name': 'Barquisimeto', 'region': 3, 'region_name': 'Centro', 'lat_range': (10.0, 10.1), 'lon_range': (-69.4, -69.3)},\n",
    "        {'name': 'Maracay', 'region': 3, 'region_name': 'Centro', 'lat_range': (10.2, 10.3), 'lon_range': (-67.6, -67.5)},\n",
    "        {'name': 'Barcelona', 'region': 4, 'region_name': 'Oriente', 'lat_range': (10.1, 10.2), 'lon_range': (-64.7, -64.6)},\n",
    "        {'name': 'Maturin', 'region': 4, 'region_name': 'Oriente', 'lat_range': (9.7, 9.8), 'lon_range': (-63.2, -63.1)}\n",
    "    ]\n",
    "    \n",
    "    formats = ['Express', 'Plus', 'Super', 'Mega']\n",
    "    layers = ['A', 'B', 'C']\n",
    "    \n",
    "    for i in range(1, n_stores + 1):\n",
    "        city = random.choice(cities)\n",
    "        store_format = random.choice(formats)\n",
    "        \n",
    "        store = {\n",
    "            'SK_ORGANIZATION': float(i),\n",
    "            'STORE_ID': float(i),\n",
    "            'STORE_NAME': f'Farmatodo {city[\"name\"]} {i}',\n",
    "            'DISTRICT': random.randint(1, 10),\n",
    "            'FORMAT_NAME': store_format,\n",
    "            'STORE_FORMAT': formats.index(store_format) + 1,\n",
    "            'DISTRICT_NAME': f'Distrito {random.randint(1, 10)}',\n",
    "            'REGION': city['region'],\n",
    "            'REGION_NAME': city['region_name'],\n",
    "            'SK_COUNTRY': SK_COUNTRY,\n",
    "            'COUNTRY_NAME': COUNTRY_NAME,\n",
    "            'CITY': city['name'],\n",
    "            'STORE_OPEN_DATE': random_date(datetime(2010, 1, 1), datetime(2023, 12, 31)),\n",
    "            'CREATED_DATE': datetime(2023, 1, 1),\n",
    "            'CREATED_BY': 'SYSTEM',\n",
    "            'LAST_UPD': datetime.now(),\n",
    "            'LAST_UPD_BY': 'SYSTEM',\n",
    "            'STORE_CLOSE_DATE': None if random.random() > 0.05 else random_date(datetime(2024, 1, 1), datetime.now()),\n",
    "            'STRATUS': random.choice(['A', 'B', 'C']),\n",
    "            'STRATUS_H': random.choice(['H1', 'H2', 'H3']),\n",
    "            'DEFAULT_WH': random.randint(1, 5),\n",
    "            'DISTRICT_MGR_NAME': fake.name(),\n",
    "            'MALL_NAME': f'C.C. {fake.company()}' if random.random() > 0.5 else None,\n",
    "            'REGION_MGR_NAME': fake.name(),\n",
    "            'SISTER_STORE': random.choice([0, random.randint(1, n_stores)]),\n",
    "            'STORE_CLASS': random.choice(['A', 'B', 'C']),\n",
    "            'STORE_MGR_NAME': fake.name(),\n",
    "            'TRANSFER_ZONE': random.randint(1, 5),\n",
    "            'VAT_REGION': city['region'],\n",
    "            'SELLING_SQUARE_ST': random.randint(800, 2500),\n",
    "            'TOTAL_SQUARE_FT': random.randint(1000, 3000),\n",
    "            'STORE_PLANNING_OPEN_DATE': random_date(datetime(2010, 1, 1), datetime(2023, 12, 31)),\n",
    "            'STORE_PLANNING_STATUS': 'OPEN',\n",
    "            'STORE_NAME_PLANNING': f'FTD_{i:03d}',\n",
    "            'STORE_ACTIVE': 'Y' if random.random() > 0.05 else 'N',\n",
    "            'GENERIC_STORE_LAYER': random.choice(layers),\n",
    "            'LATITUDE': random.uniform(*city['lat_range']),\n",
    "            'LONGITUDE': random.uniform(*city['lon_range']),\n",
    "            'CITY_ABR': city['name'][:3].upper(),\n",
    "            'STORE_INAUGURATION_DATE': random_date(datetime(2010, 1, 1), datetime(2023, 12, 31)),\n",
    "            'GENERIC_STORE_CODE': f'VE{i:04d}',\n",
    "            'LOGICAL_DISTRICT': random.randint(1, 10),\n",
    "            'LOGICAL_DISTRICT_NAME': f'Distrito Logico {random.randint(1, 10)}',\n",
    "            'LOGICAL_REGION': city['region'],\n",
    "            'LOGICAL_REGION_NAME': city['region_name'],\n",
    "            'STORE_LAYER': random.choice(layers),\n",
    "            'STORE_NAME_SECONDARY': f'FTD{i:03d}',\n",
    "            'STORE_NAME10': f'FRMTD{i:05d}',\n",
    "            'STORE_NAME3': f'F{i:02d}',\n",
    "            'VAT_INCLUDE_IND': 'Y',\n",
    "            'STORE_SUB_LAYER': f'Sub{random.choice(layers)}',\n",
    "            'STORE_SUB_LAYER_2': f'Sub2_{random.choice(layers)}',\n",
    "            'DB_EXTRACTION_TIMESTAMP': datetime.now()\n",
    "        }\n",
    "        stores.append(store)\n",
    "    \n",
    "    df = pd.DataFrame(stores)\n",
    "    \n",
    "    # Ensure column order matches table definition\n",
    "    column_order = [\n",
    "        'SK_ORGANIZATION', 'STORE_ID', 'STORE_NAME', 'DISTRICT', 'FORMAT_NAME', 'STORE_FORMAT',\n",
    "        'DISTRICT_NAME', 'REGION', 'REGION_NAME', 'SK_COUNTRY', 'COUNTRY_NAME', 'CITY',\n",
    "        'STORE_OPEN_DATE', 'CREATED_DATE', 'CREATED_BY', 'LAST_UPD', 'LAST_UPD_BY',\n",
    "        'STORE_CLOSE_DATE', 'STRATUS', 'STRATUS_H', 'DEFAULT_WH', 'DISTRICT_MGR_NAME',\n",
    "        'MALL_NAME', 'REGION_MGR_NAME', 'SISTER_STORE', 'STORE_CLASS', 'STORE_MGR_NAME',\n",
    "        'TRANSFER_ZONE', 'VAT_REGION', 'SELLING_SQUARE_ST', 'TOTAL_SQUARE_FT',\n",
    "        'STORE_PLANNING_OPEN_DATE', 'STORE_PLANNING_STATUS', 'STORE_NAME_PLANNING',\n",
    "        'STORE_ACTIVE', 'GENERIC_STORE_LAYER', 'LATITUDE', 'LONGITUDE', 'CITY_ABR',\n",
    "        'STORE_INAUGURATION_DATE', 'GENERIC_STORE_CODE', 'LOGICAL_DISTRICT',\n",
    "        'LOGICAL_DISTRICT_NAME', 'LOGICAL_REGION', 'LOGICAL_REGION_NAME', 'STORE_LAYER',\n",
    "        'STORE_NAME_SECONDARY', 'STORE_NAME10', 'STORE_NAME3', 'VAT_INCLUDE_IND',\n",
    "        'STORE_SUB_LAYER', 'STORE_SUB_LAYER_2', 'DB_EXTRACTION_TIMESTAMP'\n",
    "    ]\n",
    "    \n",
    "    return df[column_order]\n",
    "\n",
    "# ==================== DIM_TIME ====================\n",
    "def generate_dim_time(start_date=START_DATE, end_date=END_DATE):\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    time_data = []\n",
    "    \n",
    "    for date in dates:\n",
    "        sk_time = float(date.strftime('%Y%m%d'))\n",
    "        \n",
    "        time_record = {\n",
    "            'SK_TIME': sk_time,\n",
    "            'TIME_ID': date,\n",
    "            'NU_DAY': float(date.day),\n",
    "            'NU_DAY_WEEK': float(date.weekday() + 1),\n",
    "            'NB_DAY_WEEK': date.strftime('%A'),\n",
    "            'NU_WEEK_YEAR': float(date.isocalendar()[1]),\n",
    "            'NB_WEEK_YEAR': f'W{date.isocalendar()[1]:02d}',\n",
    "            'NU_MONTH': float(date.month),\n",
    "            'NB_MONTH': date.strftime('%B'),\n",
    "            'NB_MONTH_N': date.strftime('%b'),\n",
    "            'ID_MONTH': float(date.strftime('%Y%m')),\n",
    "            'MONTH_START_DATE': date.replace(day=1),\n",
    "            'MONTH_END_DATE': (date.replace(day=1) + timedelta(days=32)).replace(day=1) - timedelta(days=1),\n",
    "            'NU_QUARTER': float((date.month - 1) // 3 + 1),\n",
    "            'NB_QUARTER': f'Q{(date.month - 1) // 3 + 1}',\n",
    "            'QUARTER_START_DATE': date.replace(month=((date.month - 1) // 3) * 3 + 1, day=1),\n",
    "            'QUARTER_END_DATE': (date.replace(month=((date.month - 1) // 3) * 3 + 1, day=1) + timedelta(days=95)).replace(day=1) - timedelta(days=1),\n",
    "            'NU_YEAR': float(date.year),\n",
    "            'YEAR_START_DATE': date.replace(month=1, day=1),\n",
    "            'YEAR_END_DATE': date.replace(month=12, day=31),\n",
    "            'NU_HALF': float(1 if date.month <= 6 else 2),\n",
    "            'NB_HALF': f'H{1 if date.month <= 6 else 2}',\n",
    "            'TIME_CALENDAR': date.strftime('%Y-%m-%d'),\n",
    "            'TIME_EXCLUDE': None,\n",
    "            'CREATED_DATE': datetime(2023, 1, 1),\n",
    "            'CREATED_BY': 'SYSTEM',\n",
    "            'LAST_UPD': datetime.now(),\n",
    "            'LAST_UPD_BY': 'SYSTEM',\n",
    "            'DB_EXTRACTION_TIMESTAMP': datetime.now()\n",
    "        }\n",
    "        \n",
    "        # Add additional fields with None/default values\n",
    "        for field in ['SK_TIME_WEEK', 'SK_TIME_WEEK_YAGO', 'SK_TIME_YAGO', 'SK_TIME_YAGO_WEEK_454',\n",
    "                      'NU_YEAR_FISCAL', 'NU_QUARTER_FISCAL', 'NB_QUARTER_FISCAL', 'NU_HALF_FISCAL',\n",
    "                      'NB_HALF_FISCAL', 'NU_MONTH_454', 'NB_MONTH_454', 'ID_MONTH_454', 'NU_WEEK_454',\n",
    "                      'NB_WEEK_454', 'NU_YEAR_454', 'NU_MONTH_454_FISCAL', 'NB_MONTH_454_FISCAL',\n",
    "                      'ID_MONTH_454_FISCAL', 'NU_YEAR_454_FISCAL', 'NU_QUARTER_454_FISCAL',\n",
    "                      'NB_QUARTER_454_FISCAL', 'NU_HALF_454_FISCAL', 'NB_HALF_454_FISCAL', 'ID_PERIOD',\n",
    "                      'NU_PERIOD', 'NB_PERIOD', 'NB_MONTH_P', 'NO_OF_WEEKS', 'NU_WEEK_YEAR_FISCAL',\n",
    "                      'WEEK_START_DATE', 'WEEK_END_DATE', 'MONTH_START_DATE_454', 'MONTH_END_DATE_454',\n",
    "                      'QUARTER_FISCAL_START_DATE', 'QUARTER_FISCAL_END_DATE', 'HALF_START_DATE',\n",
    "                      'HALF_END_DATE', 'HALF_FISCAL_START_DATE', 'HALF_FISCAL_END_DATE',\n",
    "                      'YEAR_FISCAL_START_DATE', 'YEAR_FISCAL_END_DATE']:\n",
    "            time_record[field] = None\n",
    "        \n",
    "        time_data.append(time_record)\n",
    "    \n",
    "    df = pd.DataFrame(time_data)\n",
    "    \n",
    "    # Ensure column order matches table definition - using available columns\n",
    "    return df\n",
    "\n",
    "# ==================== DIM_CHANNEL ====================\n",
    "def generate_dim_channel():\n",
    "    channels = [\n",
    "        {'SK_CHANNEL': 1.0, 'CHANNEL_NAME': 'Tienda Fisica', 'CHANNEL_TYPE': 1.0, 'CHANNEL_TYPE_NAME': 'Retail', 'CHANNEL_ID': 1.0, 'CHANNEL_NAME_ORIGIN': 'STORE'},\n",
    "        {'SK_CHANNEL': 2.0, 'CHANNEL_NAME': 'E-Commerce', 'CHANNEL_TYPE': 2.0, 'CHANNEL_TYPE_NAME': 'Online', 'CHANNEL_ID': 2.0, 'CHANNEL_NAME_ORIGIN': 'WEB'},\n",
    "        {'SK_CHANNEL': 3.0, 'CHANNEL_NAME': 'App Movil', 'CHANNEL_TYPE': 2.0, 'CHANNEL_TYPE_NAME': 'Online', 'CHANNEL_ID': 3.0, 'CHANNEL_NAME_ORIGIN': 'APP'},\n",
    "        {'SK_CHANNEL': 4.0, 'CHANNEL_NAME': 'Call Center', 'CHANNEL_TYPE': 3.0, 'CHANNEL_TYPE_NAME': 'Telefonico', 'CHANNEL_ID': 4.0, 'CHANNEL_NAME_ORIGIN': 'CALL'}\n",
    "    ]\n",
    "    \n",
    "    for channel in channels:\n",
    "        channel.update({\n",
    "            'SK_COUNTRY': SK_COUNTRY,\n",
    "            'CREATED_DATE': datetime(2023, 1, 1),\n",
    "            'CREATED_BY': 'SYSTEM',\n",
    "            'LAST_UPD': datetime.now(),\n",
    "            'LAST_UPD_BY': 'SYSTEM',\n",
    "            'DB_EXTRACTION_TIMESTAMP': datetime.now()\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(channels)\n",
    "    \n",
    "    # Ensure column order matches table definition\n",
    "    column_order = [\n",
    "        'SK_CHANNEL', 'CHANNEL_NAME', 'CHANNEL_TYPE', 'CHANNEL_TYPE_NAME', 'CHANNEL_ID',\n",
    "        'SK_COUNTRY', 'LAST_UPD', 'CREATED_DATE', 'CREATED_BY', 'LAST_UPD_BY',\n",
    "        'CHANNEL_NAME_ORIGIN', 'DB_EXTRACTION_TIMESTAMP'\n",
    "    ]\n",
    "    \n",
    "    return df[column_order]\n",
    "\n",
    "# ==================== FACT_SALES_PRODUCT ====================\n",
    "def generate_fact_sales_product(dim_time, dim_product, dim_organization, dim_channel, \n",
    "                                 dim_currency, dim_supplier):\n",
    "    sales = []\n",
    "    \n",
    "    # Get active stores\n",
    "    active_stores = dim_organization[dim_organization['STORE_ACTIVE'] == 'Y']['SK_ORGANIZATION'].tolist()\n",
    "    \n",
    "    # Get active products\n",
    "    active_products = dim_product[dim_product['STATUS'] == 'A']['SK_PRODUCT'].tolist()\n",
    "    \n",
    "    # Filter time dimension for sales period\n",
    "    sales_dates = dim_time[\n",
    "        (dim_time['TIME_ID'] >= SALES_START_DATE) & \n",
    "        (dim_time['TIME_ID'] <= SALES_END_DATE)\n",
    "    ]['SK_TIME'].tolist()\n",
    "    \n",
    "    print(f\"Generating sales for {len(sales_dates)} days across {len(active_stores)} stores...\")\n",
    "    print(f\"Expected records: ~{len(sales_dates) * len(active_stores) * SALES_PER_STORE_PER_DAY:,}\")\n",
    "    \n",
    "    # Generate sales for each day and store\n",
    "    for sk_time in sales_dates:\n",
    "        business_date = dim_time[dim_time['SK_TIME'] == sk_time]['TIME_ID'].iloc[0]\n",
    "        \n",
    "        for sk_organization in active_stores:\n",
    "            # Generate multiple transactions per store per day\n",
    "            n_transactions = random.randint(\n",
    "                int(SALES_PER_STORE_PER_DAY * 0.7), \n",
    "                int(SALES_PER_STORE_PER_DAY * 1.3)\n",
    "            )\n",
    "            \n",
    "            for _ in range(n_transactions):\n",
    "                sk_product = random.choice(active_products)\n",
    "                product_info = dim_product[dim_product['SK_PRODUCT'] == sk_product].iloc[0]\n",
    "                \n",
    "                units = random.randint(1, 5)  # Most purchases are 1-5 units\n",
    "                unit_price = round(random.uniform(5, 500), 2)\n",
    "                total_sale_tax = round(units * unit_price, 2)\n",
    "                tax_rate = 0.16  # IVA Venezuela\n",
    "                tax = round(total_sale_tax * tax_rate, 2)\n",
    "                total_sale = round(total_sale_tax - tax, 2)\n",
    "                cost_margin = random.uniform(0.4, 0.7)\n",
    "                total_cost = round(total_sale * cost_margin, 2)\n",
    "                generic_cost = round(total_cost * random.uniform(0.95, 1.05), 2)\n",
    "                \n",
    "                # Weight currency selection - 70% VES, 30% USD for Venezuela\n",
    "                sk_currency = 1.0 if random.random() < 0.7 else 2.0\n",
    "                \n",
    "                sale = {\n",
    "                    'SK_TIME': sk_time,\n",
    "                    'SK_COUNTRY': SK_COUNTRY,\n",
    "                    'SK_ORGANIZATION': sk_organization,\n",
    "                    'SK_CHANNEL': random.choice(dim_channel['SK_CHANNEL'].tolist()),\n",
    "                    'SK_PRODUCT': sk_product,\n",
    "                    'SK_CURRENCY': sk_currency,\n",
    "                    'SK_SUPPLIER': product_info['BUD_INT'],\n",
    "                    'BUSINESS_DATE': business_date,\n",
    "                    'TOTAL_SALE': total_sale,\n",
    "                    'UNITS': float(units),\n",
    "                    'LAST_UPD': datetime.now(),\n",
    "                    'CREATED_DATE': business_date,\n",
    "                    'CREATED_BY': 'SYSTEM',\n",
    "                    'LAST_UPD_BY': 'SYSTEM',\n",
    "                    'SK_MODALITY': 1.0,\n",
    "                    'TOTAL_SALE_TAX': total_sale_tax,\n",
    "                    'TAX': tax,\n",
    "                    'TOTAL_COST': total_cost,\n",
    "                    'Q_TRANS': 1.0,\n",
    "                    'GENERIC_TOTAL_COST': generic_cost,\n",
    "                    'DB_EXTRACTION_TIMESTAMP': datetime.now()\n",
    "                }\n",
    "                sales.append(sale)\n",
    "    \n",
    "    df = pd.DataFrame(sales)\n",
    "    \n",
    "    # Ensure column order matches table definition\n",
    "    column_order = [\n",
    "        'SK_TIME', 'SK_COUNTRY', 'SK_ORGANIZATION', 'SK_CHANNEL', 'SK_PRODUCT', 'SK_CURRENCY',\n",
    "        'SK_SUPPLIER', 'BUSINESS_DATE', 'TOTAL_SALE', 'UNITS', 'LAST_UPD', 'CREATED_DATE',\n",
    "        'CREATED_BY', 'LAST_UPD_BY', 'SK_MODALITY', 'TOTAL_SALE_TAX', 'TAX', 'TOTAL_COST',\n",
    "        'Q_TRANS', 'GENERIC_TOTAL_COST', 'DB_EXTRACTION_TIMESTAMP'\n",
    "    ]\n",
    "    \n",
    "    return df[column_order]\n",
    "\n",
    "# ==================== MAIN EXECUTION ====================\n",
    "print(\"Generating dimensional tables...\")\n",
    "\n",
    "# Generate dimensions\n",
    "print(\"1. Generating dim_currency...\")\n",
    "dim_currency = generate_dim_currency()\n",
    "\n",
    "print(\"2. Generating dim_supplier...\")\n",
    "dim_supplier = generate_dim_supplier(n_suppliers=10)\n",
    "\n",
    "print(\"3. Generating dim_product...\")\n",
    "dim_product = generate_dim_product(n_suppliers=10, products_per_supplier=100)\n",
    "\n",
    "print(\"4. Generating dim_organization...\")\n",
    "dim_organization = generate_dim_organization(n_stores=100)\n",
    "\n",
    "print(\"5. Generating dim_time...\")\n",
    "dim_time = generate_dim_time()\n",
    "\n",
    "print(\"6. Generating dim_channel...\")\n",
    "dim_channel = generate_dim_channel()\n",
    "\n",
    "print(\"7. Generating fact_sales_product...\")\n",
    "fact_sales = generate_fact_sales_product(\n",
    "    dim_time, dim_product, dim_organization, \n",
    "    dim_channel, dim_currency, dim_supplier\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATA GENERATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"dim_currency records: {len(dim_currency)}\")\n",
    "print(f\"dim_supplier records: {len(dim_supplier)}\")\n",
    "print(f\"dim_product records: {len(dim_product)}\")\n",
    "print(f\"dim_organization records: {len(dim_organization)}\")\n",
    "print(f\"dim_time records: {len(dim_time)}\")\n",
    "print(f\"dim_channel records: {len(dim_channel)}\")\n",
    "print(f\"fact_sales_product records: {len(fact_sales)}\")\n",
    "\n",
    "# ==================== SAVE TO DATABRICKS ====================\n",
    "print(\"\\nWriting data to Databricks Delta tables...\")\n",
    "\n",
    "# Convert pandas DataFrames to Spark DataFrames\n",
    "print(\"Converting to Spark DataFrames...\")\n",
    "spark_dim_currency = spark.createDataFrame(dim_currency)\n",
    "spark_dim_supplier = spark.createDataFrame(dim_supplier)\n",
    "spark_dim_product = spark.createDataFrame(dim_product)\n",
    "spark_dim_organization = spark.createDataFrame(dim_organization)\n",
    "spark_dim_time = spark.createDataFrame(dim_time)\n",
    "spark_dim_channel = spark.createDataFrame(dim_channel)\n",
    "spark_fact_sales = spark.createDataFrame(fact_sales)\n",
    "\n",
    "# Create schema if it doesn't exist\n",
    "print(\"Ensuring workspace.operations schema exists...\")\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS workspace.operations\")\n",
    "\n",
    "# Write to Delta tables in workspace.operations schema with overwrite mode\n",
    "print(\"Writing gold_dim_currency...\")\n",
    "spark_dim_currency.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"workspace.operations.gold_dim_currency\")\n",
    "\n",
    "print(\"Writing gold_dim_supplier...\")\n",
    "spark_dim_supplier.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"workspace.operations.gold_dim_supplier\")\n",
    "\n",
    "print(\"Writing gold_dim_product...\")\n",
    "spark_dim_product.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"workspace.operations.gold_dim_product\")\n",
    "\n",
    "print(\"Writing gold_dim_organization...\")\n",
    "spark_dim_organization.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"workspace.operations.gold_dim_organization\")\n",
    "\n",
    "print(\"Writing gold_dim_time...\")\n",
    "spark_dim_time.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"workspace.operations.gold_dim_time\")\n",
    "\n",
    "print(\"Writing gold_dim_channel...\")\n",
    "spark_dim_channel.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"workspace.operations.gold_dim_channel\")\n",
    "\n",
    "print(\"Writing gold_fact_sales_product (partitioned by BUSINESS_DATE)...\")\n",
    "spark_fact_sales.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").partitionBy(\"BUSINESS_DATE\").saveAsTable(\"workspace.operations.gold_fact_sales_product\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… ALL TABLES SUCCESSFULLY WRITTEN!\")\n",
    "print(\"=\"*50)\n",
    "print(\"Schema: workspace.operations\")\n",
    "print(\"Tables created:\")\n",
    "print(\"  - gold_dim_currency\")\n",
    "print(\"  - gold_dim_supplier\")\n",
    "print(\"  - gold_dim_product\")\n",
    "print(\"  - gold_dim_organization\")\n",
    "print(\"  - gold_dim_time\")\n",
    "print(\"  - gold_dim_channel\")\n",
    "print(\"  - gold_fact_sales_product (partitioned)\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6466746488056478,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "data_generator",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
